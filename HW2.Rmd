---
title: "HW2"
output: html_document
date: '2022-04-10'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(ggplot2)
library(tidymodels)
library(tidyverse)
set.seed(45)
```


## Questions

Question 1.
```{r}
abalone <- read.csv(file = 'data/abalone.csv')
abalone['age'] <- abalone['rings'] + 1.5
ggplot(abalone, aes(x = age)) + geom_histogram()

```
It seems like the data is centered around 11, and it is quite evenly distributed.


Question 2.
```{r}
abalone2 <- subset(abalone, select = -rings)
abalone_split <- initial_split(abalone2, prop = 0.80,
                                strata = age)
abalone_train <- training(abalone_split)
abalone_test <- testing(abalone_split)
```


Question 3.

Since we defined 'age' as 'rings' + 1.5, including 'rings' variable would occur a paradox where the value that we are trying to predict is included when training the model.

```{r}
abalone_recipe <- recipe(age ~ ., data = abalone_train) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_interact(terms = ~ starts_with("type"):shucked_weight + longest_shell:diameter + 
                  shucked_weight:shell_weight) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())
```


Question 4.
```{r}
lm_model <- linear_reg() %>% 
  set_engine("lm")

lm_model
```


Question 5.
```{r}
lm_wflow <- workflow() %>% 
add_model(lm_model) %>% 
  add_recipe(abalone_recipe)

lm_wflow
```


Question 6.
```{r}
lm_fit <- fit(lm_wflow, abalone_train)
female_age <- data.frame(longest_shell = 0.50, diameter = 0.10, height = 0.30, whole_weight = 4, shucked_weight = 1, viscera_weight = 2, shell_weight = 1, type='F')

predict(lm_fit, female_age)
```


Question 7.
```{r}
abalone_train_pred <- predict(lm_fit, new_data = abalone_train %>% select(-age))
abalone_train_pred <- bind_cols(abalone_train_pred, abalone_train %>% select(age))
rmse(abalone_train_pred, truth = age, estimate = .pred)
abalone_metrics <- metric_set(rmse, rsq, mae)
abalone_metrics(abalone_train_pred, truth = age, 
                estimate = .pred)
```


Question 8.
$Var(\epsilon)$

Question 9.
If we take $\hat{f}(x_0) = E[Y|X=x_0]$,
then $E[(\hat{f}(x_0) - E\hat{f}(x_0))^2] = 0$ and $[E[\hat{f}(x_0)] - f(x_0)]^2 = 0$.
-> according to lecture note


Question 10. 
$$
\begin{aligned}
E[(y_0) - \hat{f}(x_0))^2] &= E[f(x_0) + \epsilon - \hat{f}((x_0))^2] \\
&= E[f(x_0) - \hat{f}(x_0)^2] + E[{\epsilon^2}] +2E[(f(x_0) - \hat{f}(X_0))\epsilon]\\
&= E[f(x_0) - \hat{f}(x_0)^2] + E[{\epsilon^2}] +2E[(f(x_0) - \hat{f}(X_0))]E[\epsilon] \\
&= E[(f(x_0) - \hat{f}(x_0))^2] + \sigma_{\epsilon}^2 \\
&= E[(f(x_0) - \hat{f}(x_0))^2] + Var(\epsilon)
\end{aligned}
$$

$$
\begin{aligned}
E[(f(x_0) - \hat{f}(x_0))^2] &=  E[(f(x_0) - E[\hat{f}(x_0)]) - (\hat{f}(x_0) - E[\hat{f}(x_0)])^2] \\
&= E[(E[\hat{f}(x_0)] - f(x_0))^2] + E[(\hat{f}(x_0) - E[(\hat{f}(x_0) - E[\hat{f}(x_0)])^2]  - 2E[(f(x_0) -E[\hat{f}(x_0)])(\hat{f}(x_0) - E[\hat{f}(x_0)])] \\
&= (E[\hat{f}(x_0)] - f(x_0))^2 + E[(\hat{f}(x_0) - E[\hat{f}(x_0)])^2] -2(f(x_0) - E[\hat{f}(x_0)])E[(\hat{f}(x_0) - E[\hat{f}(x_0)])] \\
&= bias[\hat{f}(x_0)]^2 + var(\hat{f}(x_0)) - 2(f(x_0) - E[\hat{f}(x_0)])(E[\hat{f}(x_0)] - E[\hat{f}(x_0)]) \\
&= bias[\hat{f}(x_0)]^2 + var(\hat{f}(x_0))
\end{aligned}
$$
Combining both results,
$$
E[(y_0) - \hat{f}(x_0))^2] = Var(\hat{f}(x_0)) + [Bias(\hat{f}(x_0))]^2 + Var(\epsilon)
$$